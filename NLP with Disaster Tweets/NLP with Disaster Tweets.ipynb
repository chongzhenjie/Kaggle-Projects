{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7584d46",
   "metadata": {
    "papermill": {
     "duration": 0.021219,
     "end_time": "2023-03-04T08:28:58.439061",
     "exception": false,
     "start_time": "2023-03-04T08:28:58.417842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Disaster Tweets â€” Basic Network Embeddings & BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7debc219",
   "metadata": {
    "papermill": {
     "duration": 0.019464,
     "end_time": "2023-03-04T08:28:58.479468",
     "exception": false,
     "start_time": "2023-03-04T08:28:58.460004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Updates: Made some parts of the code neater, and used a different set of validation data.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c916e6a",
   "metadata": {
    "papermill": {
     "duration": 0.018764,
     "end_time": "2023-03-04T08:28:58.517483",
     "exception": false,
     "start_time": "2023-03-04T08:28:58.498719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook aims to explore the functionality of the [Texthero](https://texthero.org/) package, which makes use of multiple NLP and machine learning toolkits such as Gensim, NLTK, spaCy and scikit-learn. Texthero provides functions to work with text data, and is designed to be used on top of Pandas. We will mainly use Texthero to preprocess text data.\n",
    "\n",
    "After text cleaning, we attempt to learn our own word embeddings using neural networks for text classification. Following that, we look at transfer learning through the use of pre-trained models. There are many pre-trained word embeddings like [GloVe](https://nlp.stanford.edu/projects/glove/), but we look at a more robust contextual embedding, [BERT](https://github.com/google-research/bert), which generates embeddings that takes into account the context or surrounding words, and is based on the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6297fc3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-03-04T08:28:58.558449Z",
     "iopub.status.busy": "2023-03-04T08:28:58.557354Z",
     "iopub.status.idle": "2023-03-04T08:29:44.465228Z",
     "shell.execute_reply": "2023-03-04T08:29:44.463534Z"
    },
    "papermill": {
     "duration": 45.933983,
     "end_time": "2023-03-04T08:29:44.470310",
     "exception": false,
     "start_time": "2023-03-04T08:28:58.536327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install texthero spaCy==3.3.0 gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9825a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:29:44.560920Z",
     "iopub.status.busy": "2023-03-04T08:29:44.559369Z",
     "iopub.status.idle": "2023-03-04T08:30:06.351540Z",
     "shell.execute_reply": "2023-03-04T08:30:06.350094Z"
    },
    "papermill": {
     "duration": 21.840208,
     "end_time": "2023-03-04T08:30:06.354793",
     "exception": false,
     "start_time": "2023-03-04T08:29:44.514585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import texthero as hero\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1767a1e",
   "metadata": {
    "papermill": {
     "duration": 0.027269,
     "end_time": "2023-03-04T08:30:06.409702",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.382433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03931408",
   "metadata": {
    "papermill": {
     "duration": 0.028481,
     "end_time": "2023-03-04T08:30:06.466040",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.437559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84b5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:06.525677Z",
     "iopub.status.busy": "2023-03-04T08:30:06.524278Z",
     "iopub.status.idle": "2023-03-04T08:30:06.637696Z",
     "shell.execute_reply": "2023-03-04T08:30:06.635061Z"
    },
    "papermill": {
     "duration": 0.146879,
     "end_time": "2023-03-04T08:30:06.641001",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.494122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\").drop(columns=[\"location\"])\n",
    "test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\").drop(columns=[\"location\"])\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"Dimensions of training data: {train.shape}\")\n",
    "print(f\"Dimensions of testing data: {test.shape}\")\n",
    "print(\"=\"*40)\n",
    "train.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d694605",
   "metadata": {
    "papermill": {
     "duration": 0.027752,
     "end_time": "2023-03-04T08:30:06.698297",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.670545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the problem to identify disaster tweets, we will not be using the location column. While the column may convey information on the physical location of the disaster, we can check that there are way too many unique values (almost half the training data) for the column to be useful.\n",
    "\n",
    "In contrast, the keyword column only has 222 unique values and may provide additional information that is not present in the tweet. For simplicity, we fill the missing values with an empty string to indicate the lack of a keyword. From the percentage plot below, we observe that there are many keywords which mostly belong to disaster or non-disaster tweets. \n",
    "\n",
    "However, we note that there are also a number of keywords with approximately equal proportions in both disaster and non-disaster tweets. These keywords may not be as helpful for our models. To identify the useful keywords, we need to set a threshold. Before that, we need to clean the data because some keywords like ``suicide%20bombing`` and ``suicide%20bomb`` generally refer to the same context. We look at text cleaning in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d155e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:06.757133Z",
     "iopub.status.busy": "2023-03-04T08:30:06.755877Z",
     "iopub.status.idle": "2023-03-04T08:30:06.774147Z",
     "shell.execute_reply": "2023-03-04T08:30:06.772787Z"
    },
    "papermill": {
     "duration": 0.051303,
     "end_time": "2023-03-04T08:30:06.777518",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.726215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_top_keywords(df_train, top=15, mid=0, **kwargs):\n",
    "    assert top!=0 and mid>=0. and mid<=1.\n",
    "    df = df_train.copy()\n",
    "    df_count = df.groupby(\"keyword\").target.value_counts().unstack(\"target\").fillna(0).astype(int)\n",
    "    df_prop = df.groupby(\"keyword\").target.value_counts(normalize=True).unstack(\"target\").fillna(0).sort_values(0)\n",
    "    if not mid:\n",
    "        df_plot = df_prop.iloc[:top, :].iloc[::-1] if top>0 else  df_prop.iloc[top:, :]\n",
    "    else:\n",
    "        idx = int(mid*len(df_prop.index))\n",
    "        df_plot = df_prop.iloc[idx:idx+top, :]\n",
    "    \n",
    "    df_plot.plot(\n",
    "        kind=\"barh\",\n",
    "        stacked=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "    for idx, row in df_plot.iterrows():\n",
    "        if row[0] > 0.2:\n",
    "            plt.text(\n",
    "                x=row[0]/2,\n",
    "                y=df_plot.index.tolist().index(idx),\n",
    "                s=f\"{row[0]*100:.1f}% ({df_count.loc[idx, 0]})\",\n",
    "                va=\"center\",\n",
    "                ha=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "        if row[1] > 0.2:\n",
    "            plt.text(\n",
    "                x=row[0]+row[1]/2,\n",
    "                y=df_plot.index.tolist().index(idx),\n",
    "                s=f\"{row[1]*100:.1f}% ({df_count.loc[idx, 1]})\",\n",
    "                va=\"center\",\n",
    "                ha=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "    \n",
    "    num_keyword = len(df_plot.index)\n",
    "    if not mid:\n",
    "        top_or_bot = \"Highest\" if top>0 else \"Lowest\"\n",
    "        plt.title(f\"Top {num_keyword} Keywords with {top_or_bot} % of Disaster Tweets\")\n",
    "    else:\n",
    "        plt.title(f\"Random {num_keyword} Keywords\")\n",
    "        \n",
    "    plt.xlabel(\"Proportion\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.legend([\"Not Disaster\", \"Disaster\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf312f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:06.837076Z",
     "iopub.status.busy": "2023-03-04T08:30:06.835878Z",
     "iopub.status.idle": "2023-03-04T08:30:09.194786Z",
     "shell.execute_reply": "2023-03-04T08:30:09.193517Z"
    },
    "papermill": {
     "duration": 2.396693,
     "end_time": "2023-03-04T08:30:09.202679",
     "exception": false,
     "start_time": "2023-03-04T08:30:06.805986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.keyword = train.keyword.fillna(\"\")\n",
    "test.keyword = test.keyword.fillna(\"\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "\n",
    "plot_top_keywords(train, top=15, ax=fig.add_subplot(221))\n",
    "plot_top_keywords(train, top=-15, ax=fig.add_subplot(222))\n",
    "plot_top_keywords(train, mid=0.35, ax=fig.add_subplot(223))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2666e730",
   "metadata": {
    "papermill": {
     "duration": 0.034107,
     "end_time": "2023-03-04T08:30:09.270965",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.236858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b44bc8a8",
   "metadata": {
    "papermill": {
     "duration": 0.034189,
     "end_time": "2023-03-04T08:30:09.341681",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.307492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Understanding Text Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092437a7",
   "metadata": {
    "papermill": {
     "duration": 0.033447,
     "end_time": "2023-03-04T08:30:09.409100",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.375653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now create functions for text cleaning. Our data contains the following non-exhaustive list of information:\n",
    "* Uppercased and lowercased characters,\n",
    "* Diacritics and accents,\n",
    "* Punctuation marks,\n",
    "* Blocks of digits,\n",
    "* Stopwords,\n",
    "* Words of different forms (e.g. bags vs. bag),\n",
    "* Additional whitespaces,\n",
    "* URLs,\n",
    "* HTML tags,\n",
    "* Tweet @mentions.\n",
    "\n",
    "There could be other information like emojis and spelling errors, but we will make do with the above list, which can still be managed using Texthero methods. The list of methods can be found [here](https://texthero.org/docs/api-preprocessing) and [here](https://github.com/jbesomi/texthero/blob/master/texthero/preprocessing.py), or by simply calling the ``dir()`` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89eef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:09.479540Z",
     "iopub.status.busy": "2023-03-04T08:30:09.478263Z",
     "iopub.status.idle": "2023-03-04T08:30:09.485923Z",
     "shell.execute_reply": "2023-03-04T08:30:09.484362Z"
    },
    "papermill": {
     "duration": 0.04688,
     "end_time": "2023-03-04T08:30:09.489584",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.442704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dir(hero))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "657beafd",
   "metadata": {
    "papermill": {
     "duration": 0.033655,
     "end_time": "2023-03-04T08:30:09.557128",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.523473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Depending on the context of the problem, it may be useful to standardize/remove the above information, or leave it as is. To determine the usefulness of the information, we temporarily replace them with tags (e.g. ``[PTT]`` for punctuation marks). After text cleaning, we can extract features from these tags. The functions defined for text cleaning are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814d746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:09.627767Z",
     "iopub.status.busy": "2023-03-04T08:30:09.626549Z",
     "iopub.status.idle": "2023-03-04T08:30:09.633881Z",
     "shell.execute_reply": "2023-03-04T08:30:09.632497Z"
    },
    "papermill": {
     "duration": 0.045889,
     "end_time": "2023-03-04T08:30:09.636914",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.591025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_pp(s, fn):\n",
    "    print(\"BEFORE:\")\n",
    "    print(s.values[0])\n",
    "    print(\"\\nAFTER:\")\n",
    "    print(fn(s).values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ae39061",
   "metadata": {
    "papermill": {
     "duration": 0.034022,
     "end_time": "2023-03-04T08:30:09.704779",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.670757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Coverting to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9a631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:09.777472Z",
     "iopub.status.busy": "2023-03-04T08:30:09.776761Z",
     "iopub.status.idle": "2023-03-04T08:30:09.787825Z",
     "shell.execute_reply": "2023-03-04T08:30:09.785700Z"
    },
    "papermill": {
     "duration": 0.050939,
     "end_time": "2023-03-04T08:30:09.790947",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.740008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[210], fn=hero.lowercase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d22ab02f",
   "metadata": {
    "papermill": {
     "duration": 0.034186,
     "end_time": "2023-03-04T08:30:09.859705",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.825519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing diacritics and accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12cba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:09.932471Z",
     "iopub.status.busy": "2023-03-04T08:30:09.931242Z",
     "iopub.status.idle": "2023-03-04T08:30:09.943292Z",
     "shell.execute_reply": "2023-03-04T08:30:09.941856Z"
    },
    "papermill": {
     "duration": 0.051991,
     "end_time": "2023-03-04T08:30:09.947302",
     "exception": false,
     "start_time": "2023-03-04T08:30:09.895311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[38], fn=hero.remove_diacritics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e085f6d4",
   "metadata": {
    "papermill": {
     "duration": 0.039071,
     "end_time": "2023-03-04T08:30:10.043345",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.004274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2d036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.113996Z",
     "iopub.status.busy": "2023-03-04T08:30:10.113559Z",
     "iopub.status.idle": "2023-03-04T08:30:10.119756Z",
     "shell.execute_reply": "2023-03-04T08:30:10.118264Z"
    },
    "papermill": {
     "duration": 0.045171,
     "end_time": "2023-03-04T08:30:10.122825",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.077654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_urls(s):\n",
    "    return hero.replace_urls(s, symbol=\" [URL] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9bf0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.193725Z",
     "iopub.status.busy": "2023-03-04T08:30:10.192867Z",
     "iopub.status.idle": "2023-03-04T08:30:10.203099Z",
     "shell.execute_reply": "2023-03-04T08:30:10.201715Z"
    },
    "papermill": {
     "duration": 0.051773,
     "end_time": "2023-03-04T08:30:10.208721",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.156948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[-1], fn=replace_urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f9b3ab",
   "metadata": {
    "papermill": {
     "duration": 0.03453,
     "end_time": "2023-03-04T08:30:10.278968",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.244438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ef3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.399772Z",
     "iopub.status.busy": "2023-03-04T08:30:10.399084Z",
     "iopub.status.idle": "2023-03-04T08:30:10.411655Z",
     "shell.execute_reply": "2023-03-04T08:30:10.409312Z"
    },
    "papermill": {
     "duration": 0.087786,
     "end_time": "2023-03-04T08:30:10.415533",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.327747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_html_tags(s):\n",
    "    pattern = r\"\"\"(?x)                              \n",
    "      <[^>]+>                                       \n",
    "      | &([a-z0-9]+|\\#[0-9]{1,6}|\\#x[0-9a-f]{1,6});\n",
    "      \"\"\"\n",
    "    \n",
    "    return s.str.replace(pattern, \"[HTM]\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ee108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.547624Z",
     "iopub.status.busy": "2023-03-04T08:30:10.547051Z",
     "iopub.status.idle": "2023-03-04T08:30:10.560119Z",
     "shell.execute_reply": "2023-03-04T08:30:10.558458Z"
    },
    "papermill": {
     "duration": 0.077445,
     "end_time": "2023-03-04T08:30:10.564289",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.486844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[64], fn=replace_html_tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d64ed97",
   "metadata": {
    "papermill": {
     "duration": 0.052481,
     "end_time": "2023-03-04T08:30:10.670435",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.617954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing @mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bad177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.778952Z",
     "iopub.status.busy": "2023-03-04T08:30:10.777930Z",
     "iopub.status.idle": "2023-03-04T08:30:10.790550Z",
     "shell.execute_reply": "2023-03-04T08:30:10.788585Z"
    },
    "papermill": {
     "duration": 0.072125,
     "end_time": "2023-03-04T08:30:10.795606",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.723481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_mentions(s):\n",
    "    return s.str.replace(r\"@\\w+\", \" [MTN] \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a761c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:10.904553Z",
     "iopub.status.busy": "2023-03-04T08:30:10.903953Z",
     "iopub.status.idle": "2023-03-04T08:30:10.918635Z",
     "shell.execute_reply": "2023-03-04T08:30:10.917255Z"
    },
    "papermill": {
     "duration": 0.076002,
     "end_time": "2023-03-04T08:30:10.924888",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.848886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[54], fn=replace_mentions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7296360",
   "metadata": {
    "papermill": {
     "duration": 0.062826,
     "end_time": "2023-03-04T08:30:11.040375",
     "exception": false,
     "start_time": "2023-03-04T08:30:10.977549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63165174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.121209Z",
     "iopub.status.busy": "2023-03-04T08:30:11.120452Z",
     "iopub.status.idle": "2023-03-04T08:30:11.128442Z",
     "shell.execute_reply": "2023-03-04T08:30:11.126699Z"
    },
    "papermill": {
     "duration": 0.048393,
     "end_time": "2023-03-04T08:30:11.131280",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.082887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_punctuation(s):\n",
    "    s = s.str.replace(r\"[^a-zA-Z0-9\\s\\[\\]]\", \" [PTT] \", regex=True)\n",
    "    s = s.str.replace(r\"\\[(?![A-Z]{3}\\])\", \" [PTT] \", regex=True)\n",
    "    s = s.str.replace(r\"(?<!\\[[A-Z]{3})\\]\", \" [PTT] \", regex=True)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6866e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.204514Z",
     "iopub.status.busy": "2023-03-04T08:30:11.203230Z",
     "iopub.status.idle": "2023-03-04T08:30:11.215977Z",
     "shell.execute_reply": "2023-03-04T08:30:11.213303Z"
    },
    "papermill": {
     "duration": 0.053606,
     "end_time": "2023-03-04T08:30:11.219899",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.166293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[2641], fn=replace_punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae3e554d",
   "metadata": {
    "papermill": {
     "duration": 0.035769,
     "end_time": "2023-03-04T08:30:11.291031",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.255262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19212e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.376948Z",
     "iopub.status.busy": "2023-03-04T08:30:11.375663Z",
     "iopub.status.idle": "2023-03-04T08:30:11.383056Z",
     "shell.execute_reply": "2023-03-04T08:30:11.381725Z"
    },
    "papermill": {
     "duration": 0.04814,
     "end_time": "2023-03-04T08:30:11.386004",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.337864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_digits(s):\n",
    "    return hero.replace_digits(s, symbols=\" [DIG] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fccd29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.463292Z",
     "iopub.status.busy": "2023-03-04T08:30:11.462852Z",
     "iopub.status.idle": "2023-03-04T08:30:11.474235Z",
     "shell.execute_reply": "2023-03-04T08:30:11.472450Z"
    },
    "papermill": {
     "duration": 0.057595,
     "end_time": "2023-03-04T08:30:11.479332",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.421737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[45], fn=replace_digits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52a595ef",
   "metadata": {
    "papermill": {
     "duration": 0.094893,
     "end_time": "2023-03-04T08:30:11.619628",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.524735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replacing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12836fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.698154Z",
     "iopub.status.busy": "2023-03-04T08:30:11.696940Z",
     "iopub.status.idle": "2023-03-04T08:30:11.703727Z",
     "shell.execute_reply": "2023-03-04T08:30:11.702345Z"
    },
    "papermill": {
     "duration": 0.047171,
     "end_time": "2023-03-04T08:30:11.706827",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.659656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_stopwords(s):\n",
    "    return hero.replace_stopwords(s, symbol=\" [STP] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6e0a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.780276Z",
     "iopub.status.busy": "2023-03-04T08:30:11.779834Z",
     "iopub.status.idle": "2023-03-04T08:30:11.790106Z",
     "shell.execute_reply": "2023-03-04T08:30:11.788670Z"
    },
    "papermill": {
     "duration": 0.051383,
     "end_time": "2023-03-04T08:30:11.793831",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.742448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[18], fn=replace_stopwords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1a6f8e",
   "metadata": {
    "papermill": {
     "duration": 0.036648,
     "end_time": "2023-03-04T08:30:11.866613",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.829965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Stemming words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52261aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:11.943586Z",
     "iopub.status.busy": "2023-03-04T08:30:11.942673Z",
     "iopub.status.idle": "2023-03-04T08:30:11.952516Z",
     "shell.execute_reply": "2023-03-04T08:30:11.951007Z"
    },
    "papermill": {
     "duration": 0.055594,
     "end_time": "2023-03-04T08:30:11.959137",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.903543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[14], fn=hero.stem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "096f19da",
   "metadata": {
    "papermill": {
     "duration": 0.03569,
     "end_time": "2023-03-04T08:30:12.031854",
     "exception": false,
     "start_time": "2023-03-04T08:30:11.996164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fb2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:12.107896Z",
     "iopub.status.busy": "2023-03-04T08:30:12.106658Z",
     "iopub.status.idle": "2023-03-04T08:30:12.117596Z",
     "shell.execute_reply": "2023-03-04T08:30:12.115770Z"
    },
    "papermill": {
     "duration": 0.052815,
     "end_time": "2023-03-04T08:30:12.121552",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.068737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"text\"]].iloc[7552], fn=hero.remove_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b0d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:12.199295Z",
     "iopub.status.busy": "2023-03-04T08:30:12.198056Z",
     "iopub.status.idle": "2023-03-04T08:30:12.204796Z",
     "shell.execute_reply": "2023-03-04T08:30:12.203476Z"
    },
    "papermill": {
     "duration": 0.047939,
     "end_time": "2023-03-04T08:30:12.208027",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.160088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_spaces(s):\n",
    "    return s.str.replace(r\"%20\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a225559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:12.282460Z",
     "iopub.status.busy": "2023-03-04T08:30:12.281977Z",
     "iopub.status.idle": "2023-03-04T08:30:12.292810Z",
     "shell.execute_reply": "2023-03-04T08:30:12.290499Z"
    },
    "papermill": {
     "duration": 0.053576,
     "end_time": "2023-03-04T08:30:12.297555",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.243979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pp(train[[\"keyword\"]].iloc[136], fn=remove_spaces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5173fd1b",
   "metadata": {
    "papermill": {
     "duration": 0.035995,
     "end_time": "2023-03-04T08:30:12.371089",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.335094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f05c662",
   "metadata": {
    "papermill": {
     "duration": 0.036052,
     "end_time": "2023-03-04T08:30:12.443850",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.407798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Defining Custom Pipelines for Text Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e39e4aaa",
   "metadata": {
    "papermill": {
     "duration": 0.036428,
     "end_time": "2023-03-04T08:30:12.518615",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.482187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Cleaning keywords.\n",
    "\n",
    "We first clean the keyword column before combining it with the actual tweet. We define a custom pipeline containing the relevant methods used for our problem; the functions are applied according to the order listed in the pipeline.\n",
    "\n",
    "After text cleaning, the number of unique keywords reduced from 222 to 167, indicating that many of the original keywords listed share similar information but are labeled in a different form. As described earlier, we set the threshold such that keywords with at least 70% disaster or non-disaster tweets will be combined with the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777d4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:12.594701Z",
     "iopub.status.busy": "2023-03-04T08:30:12.593497Z",
     "iopub.status.idle": "2023-03-04T08:30:12.902624Z",
     "shell.execute_reply": "2023-03-04T08:30:12.900428Z"
    },
    "papermill": {
     "duration": 0.351506,
     "end_time": "2023-03-04T08:30:12.906788",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.555282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_keywords = [\n",
    "    remove_spaces,\n",
    "    hero.remove_stopwords,\n",
    "    hero.stem,\n",
    "    hero.remove_whitespace,\n",
    "]\n",
    "\n",
    "train[\"clean_keyword\"] = hero.clean(train.keyword, pipeline=clean_keywords)\n",
    "test[\"clean_keyword\"] = hero.clean(test.keyword, pipeline=clean_keywords)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"{train.keyword.nunique()} keywords reduced to {train.clean_keyword.nunique()} keywords:\")\n",
    "print(\"=\"*40)\n",
    "print(train.clean_keyword.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10813c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:12.983031Z",
     "iopub.status.busy": "2023-03-04T08:30:12.981526Z",
     "iopub.status.idle": "2023-03-04T08:30:13.006701Z",
     "shell.execute_reply": "2023-03-04T08:30:13.005308Z"
    },
    "papermill": {
     "duration": 0.066618,
     "end_time": "2023-03-04T08:30:13.009808",
     "exception": false,
     "start_time": "2023-03-04T08:30:12.943190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESH = 0.7\n",
    "\n",
    "keyword_prop = train.groupby(\"clean_keyword\").target.value_counts(normalize=True).unstack(\"target\")\n",
    "keyword_prop = keyword_prop.fillna(0).sort_values(0)\n",
    "keywords_keep = keyword_prop[(keyword_prop[0]<=(1-THRESH)) | (keyword_prop[0]>=THRESH)].index\n",
    "\n",
    "train.clean_keyword = train.clean_keyword.apply(lambda x: x if x in keywords_keep else \"\")\n",
    "test.clean_keyword = test.clean_keyword.apply(lambda x: x if x in keywords_keep else \"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3f350fb",
   "metadata": {
    "papermill": {
     "duration": 0.036198,
     "end_time": "2023-03-04T08:30:13.082482",
     "exception": false,
     "start_time": "2023-03-04T08:30:13.046284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Cleaning text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "129b7697",
   "metadata": {
    "papermill": {
     "duration": 0.03644,
     "end_time": "2023-03-04T08:30:13.155527",
     "exception": false,
     "start_time": "2023-03-04T08:30:13.119087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " With the large amount of information to be cleaned in the actual tweet, the order of the functions listed in the pipeline is important. For example, if we replace punctuations before replacing URLs, the forward slashes ``/`` contained in URLs will be removed so the original URLs may not be recognized properly. Subsequently, we combine the keywords with the tweets by adding the keywords to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c4113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:13.232178Z",
     "iopub.status.busy": "2023-03-04T08:30:13.230856Z",
     "iopub.status.idle": "2023-03-04T08:30:18.104946Z",
     "shell.execute_reply": "2023-03-04T08:30:18.103470Z"
    },
    "papermill": {
     "duration": 4.915696,
     "end_time": "2023-03-04T08:30:18.108258",
     "exception": false,
     "start_time": "2023-03-04T08:30:13.192562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_text = [\n",
    "    hero.lowercase,\n",
    "    hero.remove_diacritics,\n",
    "    hero.remove_whitespace,\n",
    "    replace_urls,\n",
    "    replace_html_tags,\n",
    "    replace_mentions,\n",
    "    replace_punctuation,\n",
    "    replace_digits,\n",
    "    replace_stopwords,\n",
    "    hero.stem,\n",
    "    hero.remove_whitespace,\n",
    "]\n",
    "\n",
    "train[\"clean_text\"] = train.text + \" \" + train.clean_keyword\n",
    "test[\"clean_text\"] = test.text + \" \" + test.clean_keyword\n",
    "\n",
    "train.clean_text = hero.clean(train.clean_text, pipeline=clean_text)\n",
    "test.clean_text = hero.clean(test.clean_text, pipeline=clean_text)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86aab02a",
   "metadata": {
    "papermill": {
     "duration": 0.03681,
     "end_time": "2023-03-04T08:30:18.181784",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.144974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a3f39f1",
   "metadata": {
    "papermill": {
     "duration": 0.036401,
     "end_time": "2023-03-04T08:30:18.254739",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.218338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e3c2346",
   "metadata": {
    "papermill": {
     "duration": 0.037803,
     "end_time": "2023-03-04T08:30:18.329480",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.291677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extracting features from text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0db26b3",
   "metadata": {
    "papermill": {
     "duration": 0.036725,
     "end_time": "2023-03-04T08:30:18.404067",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.367342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After text cleaning, we can extract features from the text by counting the tags used to temporarily replace the corresponding information. In addition, other features like counting the number of characters or number of words (excluding the information removed) can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82f5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:18.480462Z",
     "iopub.status.busy": "2023-03-04T08:30:18.479232Z",
     "iopub.status.idle": "2023-03-04T08:30:18.489443Z",
     "shell.execute_reply": "2023-03-04T08:30:18.488130Z"
    },
    "papermill": {
     "duration": 0.051928,
     "end_time": "2023-03-04T08:30:18.492623",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.440695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    if any(\"num\" in j for j in df.columns):\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    \n",
    "    features = [\"url\", \"htm\", \"mtn\", \"ptt\", \"dig\", \"stp\"]\n",
    "    for feat in features:\n",
    "        df[f\"num_{feat}\"] = df.clean_text.apply(lambda x: x.count(f\"[{feat}]\"))\n",
    "        df.clean_text = df.clean_text.str.replace(rf\"\\[{feat}\\]\", \"\", regex=True)\n",
    "        \n",
    "    df.clean_text = hero.remove_whitespace(df.clean_text)\n",
    "    df[\"num_char\"] = (df.clean_text).apply(len)\n",
    "    df[\"num_word\"] = hero.tokenize(df.clean_text).apply(len)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2650c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:18.569036Z",
     "iopub.status.busy": "2023-03-04T08:30:18.568587Z",
     "iopub.status.idle": "2023-03-04T08:30:18.911555Z",
     "shell.execute_reply": "2023-03-04T08:30:18.908371Z"
    },
    "papermill": {
     "duration": 0.385617,
     "end_time": "2023-03-04T08:30:18.915083",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.529466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = extract_features(train)\n",
    "test = extract_features(test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "892b338b",
   "metadata": {
    "papermill": {
     "duration": 0.036846,
     "end_time": "2023-03-04T08:30:18.989221",
     "exception": false,
     "start_time": "2023-03-04T08:30:18.952375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluating usefulness of features extracted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b99422",
   "metadata": {
    "papermill": {
     "duration": 0.037517,
     "end_time": "2023-03-04T08:30:19.064526",
     "exception": false,
     "start_time": "2023-03-04T08:30:19.027009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To evaluate the usefulness of the features extracted, we look at their density plots. For a better quantification, we can estimate the mutual information, measuring the dependency between the features and the target variable. We observe that the only difference in distributions is that disaster tweets tend to contain URLs (where values are most concentrated on 1 and above), and have slightly more characters and words (where the distribution is shifted a little to the right). Otherwise, the distributions for both disaster and non-disaster tweets look similar for most features. For simplicity, we do not consider any of these features in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09930f47",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:19.142493Z",
     "iopub.status.busy": "2023-03-04T08:30:19.141183Z",
     "iopub.status.idle": "2023-03-04T08:30:19.153331Z",
     "shell.execute_reply": "2023-03-04T08:30:19.151998Z"
    },
    "papermill": {
     "duration": 0.054623,
     "end_time": "2023-03-04T08:30:19.156577",
     "exception": false,
     "start_time": "2023-03-04T08:30:19.101954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_plot(df, features):\n",
    "    df = df.copy()\n",
    "    \n",
    "    nrow = (len(features)//3) + 1\n",
    "    fig = plt.figure(figsize=(18, 4.5*nrow))\n",
    "    for i, feat in enumerate(features):\n",
    "        ax = fig.add_subplot(nrow, 3, i+1)\n",
    "        \n",
    "        sns.kdeplot(\n",
    "            x=df[feat][df.target==0],\n",
    "            fill=True,\n",
    "            lw=3,\n",
    "            ax=ax,\n",
    "            label=\"Not Disaster\",\n",
    "        )\n",
    "        # plot separately to rescale for better comparison of the distribution shape\n",
    "        sns.kdeplot(\n",
    "            x=df[feat][df.target==1],\n",
    "            fill=True,\n",
    "            lw=3,\n",
    "            ax=ax,\n",
    "            label=\"Disaster\",\n",
    "        )\n",
    "        \n",
    "        mi = mutual_info_classif(\n",
    "            X=df[feat].values.reshape(-1,1),\n",
    "            y=df.target,\n",
    "            random_state=1234,\n",
    "        )[0]\n",
    "        ax.set_title(f\"Mutual Information: {mi:.4f}\")\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d88e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:19.233757Z",
     "iopub.status.busy": "2023-03-04T08:30:19.232622Z",
     "iopub.status.idle": "2023-03-04T08:30:22.958844Z",
     "shell.execute_reply": "2023-03-04T08:30:22.957510Z"
    },
    "papermill": {
     "duration": 3.769012,
     "end_time": "2023-03-04T08:30:22.962908",
     "exception": false,
     "start_time": "2023-03-04T08:30:19.193896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_plot(train, features=[col for col in train.columns if \"num\" in col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38a281ed",
   "metadata": {
    "papermill": {
     "duration": 0.042573,
     "end_time": "2023-03-04T08:30:23.048557",
     "exception": false,
     "start_time": "2023-03-04T08:30:23.005984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Detecting *n*-grams."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d5322fd",
   "metadata": {
    "papermill": {
     "duration": 0.041827,
     "end_time": "2023-03-04T08:30:23.133545",
     "exception": false,
     "start_time": "2023-03-04T08:30:23.091718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*N*-grams are defined to be a contiguous sequence of *n* words. Because we are dealing with tweets which are generally informal and short in length, we only consider up to bigrams. We use ``hero.PhrasesTransformer()`` which wraps ``gensim.models.phrases.Phrases`` to detect bigrams based on collocation counts. The two words are concatenated together if they are detected as bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc6cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:23.226052Z",
     "iopub.status.busy": "2023-03-04T08:30:23.224815Z",
     "iopub.status.idle": "2023-03-04T08:30:24.470807Z",
     "shell.execute_reply": "2023-03-04T08:30:24.469468Z"
    },
    "papermill": {
     "duration": 1.297587,
     "end_time": "2023-03-04T08:30:24.474105",
     "exception": false,
     "start_time": "2023-03-04T08:30:23.176518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tokenized = hero.tokenize(train.clean_text)\n",
    "test_tokenized = hero.tokenize(test.clean_text)\n",
    "\n",
    "bigram_detector = hero.PhrasesTransformer()\n",
    "train_bigram = bigram_detector.fit_transform(train_tokenized)\n",
    "test_bigram = bigram_detector.transform(test_tokenized)\n",
    "\n",
    "train[\"bigram_text\"] = pd.Series(train_bigram).apply(lambda x: \" \".join(x))\n",
    "test[\"bigram_text\"] = pd.Series(test_bigram).apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88fca91b",
   "metadata": {
    "papermill": {
     "duration": 0.042095,
     "end_time": "2023-03-04T08:30:24.558749",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.516654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using the example shown below, the words ``heavy`` and ``flash`` belonging to ``heavy rain`` and ``flash flood`` could have totally different meanings by themselves depending on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65291aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:24.646032Z",
     "iopub.status.busy": "2023-03-04T08:30:24.644756Z",
     "iopub.status.idle": "2023-03-04T08:30:24.653212Z",
     "shell.execute_reply": "2023-03-04T08:30:24.651673Z"
    },
    "papermill": {
     "duration": 0.057965,
     "end_time": "2023-03-04T08:30:24.658909",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.600944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"BEFORE:\")\n",
    "print(train_tokenized[6])\n",
    "print(\"\\nAFTER:\")\n",
    "print(train_bigram[6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c12cb336",
   "metadata": {
    "papermill": {
     "duration": 0.042335,
     "end_time": "2023-03-04T08:30:24.744572",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.702237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08f1bb08",
   "metadata": {
    "papermill": {
     "duration": 0.042877,
     "end_time": "2023-03-04T08:30:24.829918",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.787041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Classifying Text with Basic Network Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f277f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:24.918587Z",
     "iopub.status.busy": "2023-03-04T08:30:24.917523Z",
     "iopub.status.idle": "2023-03-04T08:30:24.935965Z",
     "shell.execute_reply": "2023-03-04T08:30:24.934624Z"
    },
    "papermill": {
     "duration": 0.06617,
     "end_time": "2023-03-04T08:30:24.939042",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.872872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, train_labels, valid_labels = train_test_split(\n",
    "    train.drop(columns=[\"target\"]), train.target,\n",
    "    test_size=0.1,\n",
    "    stratify=train.target,\n",
    "    random_state=1234,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "519cedac",
   "metadata": {
    "papermill": {
     "duration": 0.042374,
     "end_time": "2023-03-04T08:30:25.023682",
     "exception": false,
     "start_time": "2023-03-04T08:30:24.981308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenizing text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6987c14a",
   "metadata": {
    "papermill": {
     "duration": 0.042396,
     "end_time": "2023-03-04T08:30:25.108385",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.065989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To feed text into neural networks we need to tokenize the text and then index or vectorize them. Here we are trying to learn our own word embeddings using an embedding layer, so we turn each text into a sequence of indices using ``tensorflow.keras.preprocessing.text.Tokenizer``, each unique word having its own index. We can specify the size of the vocabulary ``VOCAB_SIZE``, denoting the maximum number of words to keep based on word frequency. To ensure our text inputs are of the same size, we call ``tensorflow.keras.preprocessing.sequence.pad_sequences`` to pad or truncate each sequence to the same length. This length can be controlled by ``MAX_LENGTH``. Also, there could be words present in the validation or testing data that are not found in the training data. To allow for better learning, these missing words can be represented using a out-of-vocabulary (OOV) token ``OOV_TOK``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a0354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:25.196477Z",
     "iopub.status.busy": "2023-03-04T08:30:25.195187Z",
     "iopub.status.idle": "2023-03-04T08:30:25.461425Z",
     "shell.execute_reply": "2023-03-04T08:30:25.460052Z"
    },
    "papermill": {
     "duration": 0.313903,
     "end_time": "2023-03-04T08:30:25.464954",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.151051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LENGTH = 20\n",
    "OOV_TOK = \"[OOV]\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOK, filters=\"\")\n",
    "tokenizer.fit_on_texts(train_data.bigram_text)\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_data.bigram_text)\n",
    "train_padded = pad_sequences(train_seq, maxlen=MAX_LENGTH)\n",
    "\n",
    "valid_seq = tokenizer.texts_to_sequences(valid_data.bigram_text)\n",
    "valid_padded = pad_sequences(valid_seq, maxlen=MAX_LENGTH)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test.bigram_text)\n",
    "test_padded = pad_sequences(test_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9c1f640",
   "metadata": {
    "papermill": {
     "duration": 0.04245,
     "end_time": "2023-03-04T08:30:25.549687",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.507237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below is an example of the results from tokenization, where words like ``previouslyondoyintv``, ``makinwaua`` and ``marriag`` are not found in the training data and are thus replaced by the OOV token. By default, padding and truncating happens at the start of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc6d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:25.637701Z",
     "iopub.status.busy": "2023-03-04T08:30:25.636858Z",
     "iopub.status.idle": "2023-03-04T08:30:25.645673Z",
     "shell.execute_reply": "2023-03-04T08:30:25.644048Z"
    },
    "papermill": {
     "duration": 0.059566,
     "end_time": "2023-03-04T08:30:25.652081",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.592515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ORIGINAL CLEAN TEXT:\")\n",
    "print(test.bigram_text.iloc[17])\n",
    "print(\"\\nTOKENIZED SEQUENCE:\")\n",
    "print(test_seq[17])\n",
    "print(\"\\nPADDED SEQUENCE:\")\n",
    "print(test_padded[17].tolist())\n",
    "print(\"\\nTRANSFORMED TEXT:\")\n",
    "print(tokenizer.sequences_to_texts([test_seq[17]])[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2090003",
   "metadata": {
    "papermill": {
     "duration": 0.042588,
     "end_time": "2023-03-04T08:30:25.738265",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.695677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setting model configuration parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5fd4cdc",
   "metadata": {
    "papermill": {
     "duration": 0.042815,
     "end_time": "2023-03-04T08:30:25.824068",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.781253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For model training, we set up an exponential decay learning rate schedule and early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655017a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:25.912461Z",
     "iopub.status.busy": "2023-03-04T08:30:25.911988Z",
     "iopub.status.idle": "2023-03-04T08:30:35.819884Z",
     "shell.execute_reply": "2023-03-04T08:30:35.818464Z"
    },
    "papermill": {
     "duration": 9.956164,
     "end_time": "2023-03-04T08:30:35.823601",
     "exception": false,
     "start_time": "2023-03-04T08:30:25.867437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INIT_LR = 5e-4\n",
    "DECAY_RATE = 0.5\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lambda epoch: INIT_LR * (DECAY_RATE**epoch))\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-4, # minor improvements not considered\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "metric = F1Score(num_classes=1, threshold=0.5)\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"metrics\": [metric],\n",
    "}\n",
    "TRAIN_CONFIG = {\n",
    "    \"x\": train_padded,\n",
    "    \"y\": train_labels,\n",
    "    \"callbacks\": [lr_schedule, early_stopping],\n",
    "    \"epochs\": 50, # training stopped using early stopping\n",
    "    \"batch_size\": 16,\n",
    "    \"validation_data\": (valid_padded, valid_labels),\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "def model_predict(model, X):\n",
    "    return (model.predict(X, verbose=0)>0.5).reshape(-1,).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b6aa6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:35.912666Z",
     "iopub.status.busy": "2023-03-04T08:30:35.911456Z",
     "iopub.status.idle": "2023-03-04T08:30:35.926496Z",
     "shell.execute_reply": "2023-03-04T08:30:35.925119Z"
    },
    "papermill": {
     "duration": 0.062737,
     "end_time": "2023-03-04T08:30:35.929713",
     "exception": false,
     "start_time": "2023-03-04T08:30:35.866976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(history, true, pred):\n",
    "    num_epoch = len(history[\"loss\"])\n",
    "    xtick_freq = (num_epoch//10) + 1\n",
    "    xtick_labels = np.arange(num_epoch, step=xtick_freq, dtype=int)\n",
    "    plt.figure(figsize=(18, 4.5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.plot(history[\"loss\"], \"-o\", label = \"Training\")\n",
    "    plt.plot(history[\"val_loss\"], \"-o\", label = \"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xticks(xtick_labels, xtick_labels+1)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(history[\"f1_score\"], \"-o\", label = \"Training\")\n",
    "    plt.plot(history[\"val_f1_score\"], \"-o\", label = \"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.xticks(xtick_labels, xtick_labels+1)\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    idx = np.argmin(history[\"val_loss\"])\n",
    "    score = history[\"val_f1_score\"][idx][0]\n",
    "    cf_mat = confusion_matrix(true, pred)\n",
    "    cf_mat_norm = confusion_matrix(true, pred, normalize=\"all\")\n",
    "    labels = [f\"{ct}\\n({pt*100:.1f}%)\" for ct, pt in zip(cf_mat.ravel(), cf_mat_norm.ravel())]\n",
    "    labels = np.array(labels).reshape(2, 2)\n",
    "\n",
    "    sns.heatmap(\n",
    "        cf_mat,\n",
    "        annot=labels,\n",
    "        cmap=\"Blues\",\n",
    "        fmt=\"\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Validation F1 Score: {score:.4f}\")\n",
    "    \n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4f1ca2d",
   "metadata": {
    "papermill": {
     "duration": 0.049946,
     "end_time": "2023-03-04T08:30:36.022595",
     "exception": false,
     "start_time": "2023-03-04T08:30:35.972649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building network architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe6a94b8",
   "metadata": {
    "papermill": {
     "duration": 0.043087,
     "end_time": "2023-03-04T08:30:36.109415",
     "exception": false,
     "start_time": "2023-03-04T08:30:36.066328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Neural network embeddings provide a method to represent discrete variables as continuous vectors. Here we are trying to learn continuous vector representations of each word. This helps reduce dimensionality, compared to other methods like one-hot embedding which maps each word to a different vector. Moreover, the vectors of words that share similar meaning in the given context will be closer in the embedding space.\n",
    "\n",
    "To build the model, we first define an embedding layer that turns the text input into vectors of dimensions specified by ``output_dim``. As this is a binary classification problem, the output layer has simply 1 unit, with a sigmoid activation function mapping the output to a probability value. We look at using different layers after the embedding layer:\n",
    "* **Bidirectional GRU** â€” connects 2 GRU layers of opposite directions to the next layer. This has the advantage of getting information from past and future states simultaneously, effectively understanding the words in context.\n",
    "* **Convolution + global average pooling**. The convolution layer extracts features while the global average pooling layer condenses the information of each feature map.\n",
    "\n",
    "For simplicity, we do not add additional layers, and the models are manually tuned. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bc38c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:36.197061Z",
     "iopub.status.busy": "2023-03-04T08:30:36.196615Z",
     "iopub.status.idle": "2023-03-04T08:30:36.206252Z",
     "shell.execute_reply": "2023-03-04T08:30:36.204789Z"
    },
    "papermill": {
     "duration": 0.056943,
     "end_time": "2023-03-04T08:30:36.209227",
     "exception": false,
     "start_time": "2023-03-04T08:30:36.152284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_gru():\n",
    "    gru_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, output_dim=16, input_length=MAX_LENGTH),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16, dropout=0.4)),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    gru_model.compile(**MODEL_CONFIG)\n",
    "    \n",
    "    return gru_model\n",
    "\n",
    "def build_cnn():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, output_dim=16, input_length=MAX_LENGTH),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    cnn_model.compile(**MODEL_CONFIG)\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e3a4d1",
   "metadata": {
    "papermill": {
     "duration": 0.043646,
     "end_time": "2023-03-04T08:30:36.295527",
     "exception": false,
     "start_time": "2023-03-04T08:30:36.251881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de735ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:30:36.383438Z",
     "iopub.status.busy": "2023-03-04T08:30:36.382958Z",
     "iopub.status.idle": "2023-03-04T08:31:42.608896Z",
     "shell.execute_reply": "2023-03-04T08:31:42.607499Z"
    },
    "papermill": {
     "duration": 66.320361,
     "end_time": "2023-03-04T08:31:42.658747",
     "exception": false,
     "start_time": "2023-03-04T08:30:36.338386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_model = build_gru()\n",
    "gru_history = gru_model.fit(**TRAIN_CONFIG).history\n",
    "\n",
    "model_eval(gru_history, valid_labels, model_predict(gru_model, valid_padded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "287b5371",
   "metadata": {
    "papermill": {
     "duration": 0.044454,
     "end_time": "2023-03-04T08:31:42.748263",
     "exception": false,
     "start_time": "2023-03-04T08:31:42.703809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46544b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:31:42.841090Z",
     "iopub.status.busy": "2023-03-04T08:31:42.839889Z",
     "iopub.status.idle": "2023-03-04T08:32:18.316253Z",
     "shell.execute_reply": "2023-03-04T08:32:18.314495Z"
    },
    "papermill": {
     "duration": 35.574458,
     "end_time": "2023-03-04T08:32:18.367558",
     "exception": false,
     "start_time": "2023-03-04T08:31:42.793100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_model = build_cnn()\n",
    "cnn_history = cnn_model.fit(**TRAIN_CONFIG).history\n",
    "\n",
    "model_eval(cnn_history, valid_labels, model_predict(cnn_model, valid_padded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfe235ad",
   "metadata": {
    "papermill": {
     "duration": 0.046657,
     "end_time": "2023-03-04T08:32:18.461118",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.414461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56c47214",
   "metadata": {
    "papermill": {
     "duration": 0.046849,
     "end_time": "2023-03-04T08:32:18.555497",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.508648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Classifying Text with BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b6182f8",
   "metadata": {
    "papermill": {
     "duration": 0.124918,
     "end_time": "2023-03-04T08:32:18.727745",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.602827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are many different BERT models that can be loaded from [TensorFlow Hub](https://tfhub.dev/) together with their corresponding preprocessing models. We can try different models by simply changing the below URLs to be loaded from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0e80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:32:18.825291Z",
     "iopub.status.busy": "2023-03-04T08:32:18.824018Z",
     "iopub.status.idle": "2023-03-04T08:32:18.830818Z",
     "shell.execute_reply": "2023-03-04T08:32:18.829272Z"
    },
    "papermill": {
     "duration": 0.058897,
     "end_time": "2023-03-04T08:32:18.833910",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.775013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HANDLE_PREPROCESS = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "HANDLE_ENCODER = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13fd9a3c",
   "metadata": {
    "papermill": {
     "duration": 0.047124,
     "end_time": "2023-03-04T08:32:18.928148",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.881024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding preprocessing model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc1e8c04",
   "metadata": {
    "papermill": {
     "duration": 0.048401,
     "end_time": "2023-03-04T08:32:19.023824",
     "exception": false,
     "start_time": "2023-03-04T08:32:18.975423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 3 outputs from preprocessing, which would then be used as inputs for the BERT model: ``input_word_ids`` is the unique index for each tokenized input, ``input_mask`` differentiates non-padding from padding tokens, and ``input_type_ids`` distinguishes multiple text segments per input. The input is truncated to 128 tokens by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a130a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:32:19.121432Z",
     "iopub.status.busy": "2023-03-04T08:32:19.120957Z",
     "iopub.status.idle": "2023-03-04T08:32:25.214785Z",
     "shell.execute_reply": "2023-03-04T08:32:25.212913Z"
    },
    "papermill": {
     "duration": 6.146282,
     "end_time": "2023-03-04T08:32:25.217939",
     "exception": false,
     "start_time": "2023-03-04T08:32:19.071657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_preprocessor = hub.KerasLayer(HANDLE_PREPROCESS)\n",
    "example_input = bert_preprocessor([train.text.values[0]])\n",
    "\n",
    "print(\"input_word_ids: \", example_input[\"input_word_ids\"].numpy().tolist())\n",
    "print(\"\\ninput_mask    : \", example_input[\"input_mask\"].numpy().tolist())\n",
    "print(\"\\ninput_type_ids: \", example_input[\"input_type_ids\"].numpy().tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23a5151f",
   "metadata": {
    "papermill": {
     "duration": 0.047475,
     "end_time": "2023-03-04T08:32:25.312551",
     "exception": false,
     "start_time": "2023-03-04T08:32:25.265076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding BERT model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac080bd3",
   "metadata": {
    "papermill": {
     "duration": 0.047259,
     "end_time": "2023-03-04T08:32:25.407321",
     "exception": false,
     "start_time": "2023-03-04T08:32:25.360062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The BERT model also returns 3 outputs: ``pooled_output`` can be regarded as the embedding for each tweet, ``sequence_output`` can be considered the embedding for every token in each tweet, and ``encoder_outputs`` are the intermediate activations of the Transformer blocks. We are mainly concerned with ``pooled_output`` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122d4d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:32:25.506094Z",
     "iopub.status.busy": "2023-03-04T08:32:25.504927Z",
     "iopub.status.idle": "2023-03-04T08:33:47.237510Z",
     "shell.execute_reply": "2023-03-04T08:33:47.236006Z"
    },
    "papermill": {
     "duration": 81.834361,
     "end_time": "2023-03-04T08:33:47.289053",
     "exception": false,
     "start_time": "2023-03-04T08:32:25.454692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_encoder = hub.KerasLayer(HANDLE_ENCODER)\n",
    "example_output = bert_encoder(example_input)\n",
    "\n",
    "print(\"pooled_output shape  : \", example_output[\"pooled_output\"].shape)\n",
    "print(\"sequence_output shape: \", example_output[\"sequence_output\"].shape)\n",
    "print(f\"encoder_outputs shape: {len(example_output['encoder_outputs'])} Tensors with shape\", example_output[\"encoder_outputs\"][0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b00e77",
   "metadata": {
    "papermill": {
     "duration": 0.04867,
     "end_time": "2023-03-04T08:33:47.386093",
     "exception": false,
     "start_time": "2023-03-04T08:33:47.337423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building network architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b105d5ef",
   "metadata": {
    "papermill": {
     "duration": 0.049572,
     "end_time": "2023-03-04T08:33:47.483809",
     "exception": false,
     "start_time": "2023-03-04T08:33:47.434237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We build a [simple model](https://www.tensorflow.org/text/tutorials/classify_text_with_bert#define_your_model) using only the preprocessing model, the BERT model, and the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796509a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:33:47.582300Z",
     "iopub.status.busy": "2023-03-04T08:33:47.581833Z",
     "iopub.status.idle": "2023-03-04T08:33:47.590849Z",
     "shell.execute_reply": "2023-03-04T08:33:47.589367Z"
    },
    "papermill": {
     "duration": 0.061766,
     "end_time": "2023-03-04T08:33:47.593670",
     "exception": false,
     "start_time": "2023-03-04T08:33:47.531904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_bert():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "    bert_preprocessor = hub.KerasLayer(HANDLE_PREPROCESS)\n",
    "    encoder_inputs = bert_preprocessor(text_input)\n",
    "    bert_encoder = hub.KerasLayer(HANDLE_ENCODER, trainable=True)\n",
    "    outputs = bert_encoder(encoder_inputs)\n",
    "    net = outputs[\"pooled_output\"]\n",
    "    net = tf.keras.layers.Dense(1, activation=\"sigmoid\")(net)\n",
    "    \n",
    "    bert_model = tf.keras.Model(text_input, net)\n",
    "    bert_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[metric],\n",
    "    )\n",
    "    \n",
    "    return bert_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60a25897",
   "metadata": {
    "papermill": {
     "duration": 0.047192,
     "end_time": "2023-03-04T08:33:47.688175",
     "exception": false,
     "start_time": "2023-03-04T08:33:47.640983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64bc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T08:33:47.786168Z",
     "iopub.status.busy": "2023-03-04T08:33:47.785713Z",
     "iopub.status.idle": "2023-03-04T09:02:05.342322Z",
     "shell.execute_reply": "2023-03-04T09:02:05.339375Z"
    },
    "papermill": {
     "duration": 1697.781806,
     "end_time": "2023-03-04T09:02:05.517767",
     "exception": false,
     "start_time": "2023-03-04T08:33:47.735961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_model = build_bert()\n",
    "\n",
    "early_stopping.patience = 1 # training stopped if current epoch shows no improvement\n",
    "bert_history = bert_model.fit(\n",
    "    x=train_data.text, # original text column used\n",
    "    y=train_labels,\n",
    "    epochs=50, # training stopped using early stopping\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=16,\n",
    "    validation_data=(valid_data.text, valid_labels),\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c486e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T09:02:05.854254Z",
     "iopub.status.busy": "2023-03-04T09:02:05.853813Z",
     "iopub.status.idle": "2023-03-04T09:02:23.076652Z",
     "shell.execute_reply": "2023-03-04T09:02:23.075212Z"
    },
    "papermill": {
     "duration": 17.393537,
     "end_time": "2023-03-04T09:02:23.080225",
     "exception": false,
     "start_time": "2023-03-04T09:02:05.686688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_eval(bert_history, valid_labels, model_predict(bert_model, valid_data.text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0baf7737",
   "metadata": {
    "papermill": {
     "duration": 0.168558,
     "end_time": "2023-03-04T09:02:23.422821",
     "exception": false,
     "start_time": "2023-03-04T09:02:23.254263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb66367",
   "metadata": {
    "papermill": {
     "duration": 0.166851,
     "end_time": "2023-03-04T09:02:23.762448",
     "exception": false,
     "start_time": "2023-03-04T09:02:23.595597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a993066c",
   "metadata": {
    "papermill": {
     "duration": 0.169391,
     "end_time": "2023-03-04T09:02:24.099324",
     "exception": false,
     "start_time": "2023-03-04T09:02:23.929933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The pre-trained BERT model achieved a much better performance, showing the benefits of transfer learning. We use it as the final model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14ff77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T09:02:24.444523Z",
     "iopub.status.busy": "2023-03-04T09:02:24.443764Z",
     "iopub.status.idle": "2023-03-04T09:03:46.467019Z",
     "shell.execute_reply": "2023-03-04T09:03:46.465610Z"
    },
    "papermill": {
     "duration": 82.368991,
     "end_time": "2023-03-04T09:03:46.636774",
     "exception": false,
     "start_time": "2023-03-04T09:02:24.267783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test.id,\n",
    "    \"target\": model_predict(bert_model, test.text),\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28af99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T09:03:46.972575Z",
     "iopub.status.busy": "2023-03-04T09:03:46.971317Z",
     "iopub.status.idle": "2023-03-04T09:03:46.989812Z",
     "shell.execute_reply": "2023-03-04T09:03:46.988365Z"
    },
    "papermill": {
     "duration": 0.19069,
     "end_time": "2023-03-04T09:03:46.993513",
     "exception": false,
     "start_time": "2023-03-04T09:03:46.802823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2def8cd9",
   "metadata": {
    "papermill": {
     "duration": 0.234984,
     "end_time": "2023-03-04T09:03:47.395581",
     "exception": false,
     "start_time": "2023-03-04T09:03:47.160597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2106.976333,
   "end_time": "2023-03-04T09:03:51.323454",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-04T08:28:44.347121",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
